{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import scipy\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# State space\n",
    "We need to specify the size of the state space.\n",
    "Suppose the value of a worm is $6$.\n",
    "\n",
    "We define two kinds of state, two kinds of action, and two kinds of transition matrices : the state in which we need to choose whether or not to throw the remaining dice, and the state in which we need to decide which dice to pick.\n",
    "\n",
    "\n",
    "A state can be described by:\n",
    "1. The current sum of values of the dice drawn.\n",
    "2. The values of dice already picked\n",
    "3. Nb de dés restants\n",
    "4. Le fait qu'on ait fait un tirage ou pas, et la valeur du tirage le cas échéant\n",
    "\n",
    "For state $s_1$:\n",
    "\n",
    "1. Current value: $49$ possible values + $1$ absorbing state\n",
    "2. Current dice values picked: $2^6$ possible values\n",
    "3. Number of remaining dice: $9$ possible values\n",
    "\n",
    "total : $28224$\n",
    "\n",
    "For state $s_2$:\n",
    "1. Current value: $49$ possible values\n",
    "2. Current dice values picked: $2^6$ possible values\n",
    "3. Number of remaining dice: $9$ possible values\n",
    "4. Dice drawn: $\\binom{14}{6}$ possible values (sticks and stones)\n",
    "\n",
    "total : $49\\times 2^6 \\times 9 \\times \\binom{14}{6}= 84,756,672$\n",
    "\n",
    "Possible actions after $s_1$:\n",
    "\n",
    "1. Throw the dice or not\n",
    "\n",
    "total: $2$\n",
    "\n",
    "Possible actions after $s_2$:\n",
    "\n",
    "1. Pick any of the numbers. If we pick an unavailable value, we lose (negative reward + we get into the absorbing state with $0$ dice remaining)\n",
    "\n",
    "total: $6$\n",
    "\n",
    "\n",
    "On ne peut pas matérialiser la matrice de transition de l'état $s_1$ à l'état $s_2$: ça ferait\n",
    "$(49\\times 2^6 \\times 9)^2 \\times \\binom{14}{6}*2 = 4.784344621056 × 10^{12}$\n",
    "\n",
    "Mais on n'est pas obligés d'avoir $2$ matrices d'états différents : on peut obliger l'agent à prendre la décision sans connaître le résultat du lancer.\n",
    "\n",
    "On suppose qu'un tour est composé de $6\\times 2$ actions, car il y a seulement $6$ valeurs de dés possibles.\n",
    "\n",
    "Il faut donc calculer pour chacun des $6$ tours, la valeur de chaque état récursivement.\n",
    "\n",
    "On doit créer un état absorbant qui signifie que le joueur a perdu suite à une action interdite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "interval_1 = int(scipy.special.binom(9,1))# Etats où on a de 0 à 8 fois le dé 1\n",
    "interval_2 = int(scipy.special.binom(10,2))# Etats où on a de 0 à 8 fois le dé 1 et de 0 à 8 fois le dé 2\n",
    "interval_3 = int(scipy.special.binom(11,3))# Etats où on a de 0 à 8 fois le dé 1 et de 0 à 8 fois le dé 2 et de 0 à 8 fois le dé 3\n",
    "interval_4 = int(scipy.special.binom(12,4))\n",
    "interval_5 = int(scipy.special.binom(13,5))\n",
    "interval_6 = int(scipy.special.binom(14,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "intervals_6 = [int(scipy.special.binom(i,5)) for i in range(13,5,-1)]\n",
    "c_intervals_6 = np.cumsum(intervals_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_partition():\n",
    "    \"\"\"Via la hockey stick identity, on construit l'ensemble des jetés de dés.\"\"\"\n",
    "    dict_index = {}\n",
    "    for i_0 in range(9):\n",
    "        for i_1 in range(9-i_0):\n",
    "            for i_2 in range(9-i_0-i_1):\n",
    "                for i_3 in range(9-i_0-i_1-i_2):\n",
    "                    for i_4 in range(9-i_0-i_1-i_2-i_3):\n",
    "                        for i_5 in range(9-i_0-i_1-i_2-i_3-i_4):\n",
    "                            i_6 = 8-i_0-i_1-i_2-i_3-i_4-i_5\n",
    "                            dict_index[((i_0,i_1,i_2,i_3,i_4,i_5,i_6))] = len(dict_index)\n",
    "    return dict_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_index = index_partition()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_number = {v: k for k, v in dict_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_numbers = list(dict_number.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "reward_vector = torch.zeros(50)\n",
    "reward_vector[21:25] = 1\n",
    "reward_vector[25:29] = 2\n",
    "reward_vector[29:33] = 3\n",
    "reward_vector[33:37] = 4"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il y a deux cas : soit on choisit un nombre inacceptable et on va dans l'état $50$, soit on choisit un nombre acceptable, et en fonction du nombre choisi, on doit calculer la nouvelle valeur totale que l'on a, le nouveau nombre de dés restants, et mettre à jour les dés déjà obtenus (en passant simplement de l'état $n$ à $n+2^{c-1}$ où $c$ est la valeur du dé choisi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimal_choice_1(state, action):\n",
    "    # state is a vector (value, dice_values_picked, remaining_dice)\n",
    "    # action is a value 0-1, representing whether to continue or not.\n",
    "    value, dice_values_picked, dice_owned, draw_result = state\n",
    "    dice_left = 8 - dice_owned\n",
    "    if action == 0 or dice_left == 0:\n",
    "        if dice_values_picked[-1] == 0:\n",
    "            # We choose to stop but have no pickominos\n",
    "            return c\n",
    "        else:\n",
    "            # We have found at least one pickomino\n",
    "            return reward_vector[value]\n",
    "    elif action == 1:\n",
    "        # We choose to continue and have remaining dice\n",
    "        list_draws = list_numbers[c_intervals_6[dice_owned]:c_intervals_6[dice_owned+1]]\n",
    "        list_values = []\n",
    "        for draw in list_draws:\n",
    "            new_state = value, dice_values_picked, dice_owned, draw\n",
    "            maximum_value = max([optimal_choice_2(new_state, i) for i in range(1,7)])\n",
    "            list_values.append(maximum_value)\n",
    "        print(list_values)\n",
    "        print(f\"{np.mean(list_values)=}\")\n",
    "        return np.mean(list_values)\n",
    "        \n",
    "\n",
    "def optimal_choice_2(state, action):\n",
    "    # state is a vector (value, dice_values_picked, remaining_dice, draw_result)\n",
    "    # here dice_values_picked is a vector of 6 values 0-1, representing whether the dice has been picked or not.\n",
    "    # action is a number 0-6 representing the choice of dice to keep, or whether to not pick any dice.\n",
    "    value, dice_values_picked, dice_owned, draw_result = state\n",
    "    draw_values = draw_result\n",
    "    if draw_values[action] == 0:\n",
    "        return c\n",
    "    else:\n",
    "        if dice_values_picked[action-1] == 1:\n",
    "            return c\n",
    "        else:\n",
    "            dice_values_picked[action-1] = 1\n",
    "            new_state = value + min(action,5)*draw_values[action], dice_values_picked, dice_owned + draw_values[action], draw_result\n",
    "            choices = [optimal_choice_1(new_state, 0), optimal_choice_1(new_state, 1)]\n",
    "            return max(choices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = -3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_start_1(state):\n",
    "    list_action_results = [optimal_choice_1(state, action) for action in range(2)]\n",
    "    return max(list_action_results)\n",
    "\n",
    "def max_start_2(state):\n",
    "    list_action_results = [optimal_choice_2(state, action) for action in range(1,7)]\n",
    "    return max(list_action_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0]\n",
      "np.mean(list_values)=0.0\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, tensor(2.), 0, 0, 0, 0, 0]\n",
      "np.mean(list_values)=0.09523809523809523\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, tensor(2.), 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "np.mean(list_values)=0.03571428571428571\n",
      "[0, tensor(2.), 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "np.mean(list_values)=0.015873015873015872\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.015873015873015872"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value_2 = 20\n",
    "dice_values_picked_2 = [0,0,1,1,0,1]\n",
    "dice_owned_2 = 4\n",
    "draw_result_2 = (6,0,0,0,0,0,2)\n",
    "\n",
    "state_2 = value_2, dice_values_picked_2, dice_owned_2, draw_result_2\n",
    "max_start_1(state_2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
